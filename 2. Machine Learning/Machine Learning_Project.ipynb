{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f78f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Classification Report ***\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Real (OR)       0.53      0.50      0.51      4044\n",
      "   Fake (CG)       0.53      0.56      0.55      4043\n",
      "\n",
      "    accuracy                           0.53      8087\n",
      "   macro avg       0.53      0.53      0.53      8087\n",
      "weighted avg       0.53      0.53      0.53      8087\n",
      "\n",
      "*** Confusion Matrix ***\n",
      "[[2012 2032]\n",
      " [1765 2278]]\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split # For splitting data\n",
    "from sklearn.linear_model import LogisticRegression # ML model\n",
    "from sklearn.metrics import classification_report, confusion_matrix #Evaluation metrics\n",
    "\n",
    "# 1) Load raw CSV\n",
    "df = pd.read_csv(\"Data/fake reviews dataset.csv\")\n",
    "\n",
    "# 2) Rename the text column for convenience\n",
    "df.rename(columns={'text_': 'text'}, inplace=True)\n",
    "\n",
    "# 3) Define a text-cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()                        # lowercase\n",
    "    text = re.sub(r'<.*?>', '', text)          # remove HTML tags\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)       # drop punctuation/numbers\n",
    "    return text.strip()\n",
    "\n",
    "# 4) Apply cleaning and Feature Engineering\n",
    "df['cleaned_text'] = df['text'].apply(clean_text) # apply cleaning\n",
    "df['review_length'] = df['cleaned_text'].apply(lambda t: len(t.split())) # number of words\n",
    "df['sentiment'] = df['cleaned_text'].apply(lambda t: TextBlob(t).sentiment.polarity) # sentiment score\n",
    "\n",
    "# 5) Prepare feature matrix X and target y\n",
    "X = df[['review_length', 'rating', 'sentiment']]\n",
    "y = df['label'].map({'CG': 1, 'OR': 0})  # CG = fake (1), OR = real (0)\n",
    "\n",
    "# 6) Split into train and test sets (80/20, stratified to keep labels balanced)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 7) Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000) #create model\n",
    "clf.fit(X_train, y_train) #train on training data\n",
    "\n",
    "# 8) Evaluate on the test set\n",
    "y_pred = clf.predict(X_test) # make prediction on the test set\n",
    "print(\"*** Classification Report ***\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real (OR)\", \"Fake (CG)\"]))\n",
    "print(\"*** Confusion Matrix ***\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e4eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>review_length</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5       5    CG   \n",
       "1  Home_and_Kitchen_5       5    CG   \n",
       "2  Home_and_Kitchen_5       5    CG   \n",
       "3  Home_and_Kitchen_5       1    CG   \n",
       "4  Home_and_Kitchen_5       5    CG   \n",
       "\n",
       "                                                text  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "                                        cleaned_text  review_length  sentiment  \n",
       "0  love this  well made sturdy and very comfortab...             12   0.442500  \n",
       "1  love it a great upgrade from the original  ive...             16   0.558333  \n",
       "2  this pillow saved my back i love the look and ...             14   0.250000  \n",
       "3  missing information on how to use it but it is...             17   0.300000  \n",
       "4  very nice set good quality we have had the set...             18   0.740000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show info of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb06cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold F1 scores: [0.90189219 0.88817891 0.88692863 0.8925144  0.89624443]\n",
      "Mean F1 score  : 0.893151712171402\n",
      "\n",
      "*** Test Set Classification Report ***\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Real (OR)       0.88      0.94      0.91      4044\n",
      "   Fake (CG)       0.93      0.87      0.90      4043\n",
      "\n",
      "    accuracy                           0.90      8087\n",
      "   macro avg       0.90      0.90      0.90      8087\n",
      "weighted avg       0.90      0.90      0.90      8087\n",
      "\n",
      "*** Test Set Confusion Matrix ***\n",
      "[[3788  256]\n",
      " [ 528 3515]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "# Captures word frequency importance\n",
    "# Limitations: Doesn't capture word order or context\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline                                   # Combine preprocessign and modeling\n",
    "from sklearn.compose import ColumnTransformer                           # Different preprocessign for different columns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer             # TF-IDF for text vectorization\n",
    "from sklearn.preprocessing import StandardScaler                        # Normalize numerical features\n",
    "from sklearn.ensemble import RandomForestClassifier                     # Classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix     # EValuate metrics\n",
    "\n",
    "# 1) Load raw data\n",
    "df = pd.read_csv(\"Data/fake reviews dataset.csv\")\n",
    "\n",
    "# 2) Rename the text column\n",
    "df.rename(columns={'text_': 'text'}, inplace=True)\n",
    "\n",
    "# 3) Clean text and compute EDA features\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)    # strip HTML\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) # keep only letters/spaces\n",
    "    return text.strip()\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "df['review_length'] = df['cleaned_text'].apply(lambda t: len(t.split()))\n",
    "df['sentiment']     = df['cleaned_text'].apply(lambda t: TextBlob(t).sentiment.polarity)\n",
    "\n",
    "# 4) Prepare features (including the raw cleaned_text) and labels\n",
    "X = df[['cleaned_text', 'review_length', 'rating', 'sentiment']]\n",
    "y = df['label'].map({'CG': 1, 'OR': 0})  # 1=fake, 0=real\n",
    "\n",
    "# 5) Split into train/test (80/20, stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 6) Build a ColumnTransformer that:\n",
    "#    - vectorizes the cleaned_text via TF-IDF (unigrams + bigrams)\n",
    "#    - standardizes the numeric features\n",
    "#    - TF-IDF (Text Feature Extraction): transforms the review text into numerical vectors\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"tfidf\",  TfidfVectorizer(max_features=5000, ngram_range=(1,2)), 'cleaned_text'), # n-gram range(1,2) captures both single words and bigrams \n",
    "    (\"scale\",  StandardScaler(), ['review_length', 'rating', 'sentiment'])\n",
    "])\n",
    "\n",
    "# 7) Create a full Pipeline: preprocessor + classifier\n",
    "#    - Random Forest Classifier: a powerful ensemble classifier based on decision trees\n",
    "#    - It works well with mixed types of data (text + numeric)\n",
    "pipeline = Pipeline([('preprocessing', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 8) 5-fold cross-validation on the training set\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "print(\"5-fold F1 scores:\", cv_scores)\n",
    "print(\"Mean F1 score  :\", cv_scores.mean())\n",
    "\n",
    "# 9) Fit on training data and evaluate on test data\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\n*** Test Set Classification Report ***\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real (OR)\", \"Fake (CG)\"]))\n",
    "print(\"*** Test Set Confusion Matrix ***\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796d367",
   "metadata": {},
   "source": [
    "- F1 scores across the 5 folds are all around 0.89-0.90, showing stable performance\n",
    "\n",
    "- A mean F1 = 0.89 indicates that, on average, about 89-90% of the labels are being correctly classified when I cross-validate on the training data\n",
    "\n",
    "- Test-Set Performance: \n",
    "- Accuracy = 0.90\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
